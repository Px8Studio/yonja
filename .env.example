# ALIM AI Environment Configuration
# Copy this file to .env and customize values
# All variables use ALIM_ prefix

# ===========================================
# Deployment (Two-Axis Model)
# ===========================================
# Axis 1: Environment — WHAT stage of development
ALIM_ENVIRONMENT=development  # development | staging | production

# Axis 2: Infrastructure Mode — WHERE it runs
ALIM_INFRASTRUCTURE_MODE=local  # local | cloud

# DEPRECATED: Use Environment + InfrastructureMode instead
ALIM_DEPLOYMENT_MODE=open_source

# Debug mode (auto-enabled in ALIM_ENVIRONMENT=development)
ALIM_DEBUG=false

# ===========================================
# LangGraph Server (Required for HTTP Mode)
# ===========================================
# When true, LangGraph Dev Server must be running (recommended)
# When false, falls back to in-process execution (legacy direct mode)
ALIM_LANGGRAPH_REQUIRED=true
ALIM_LANGGRAPH_BASE_URL=http://127.0.0.1:2024
ALIM_LANGGRAPH_GRAPH_ID=yonca_agent

# ===========================================
# API Settings
# ===========================================
ALIM_API_HOST=0.0.0.0
ALIM_API_PORT=8000
ALIM_API_WORKERS=4
ALIM_CORS_ORIGINS=["http://localhost:3000", "http://localhost:8501"]

# ===========================================
# LLM Provider Configuration
# ===========================================
# Choose: ollama (local/slow), groq (cloud/ultra-fast), vllm (self-hosted)
ALIM_LLM_PROVIDER=ollama

# Ollama (Local)
ALIM_OLLAMA_BASE_URL=http://localhost:11434
ALIM_OLLAMA_MODEL=qwen3:4b

# Groq (Cloud) - Free Tier
ALIM_GROQ_API_KEY=
ALIM_GROQ_MODEL=meta-llama/llama-4-maverick-17b-128e-instruct

# vLLM (DigiRella Cloud / Self-Hosted)
ALIM_VLLM_BASE_URL=
ALIM_VLLM_MODEL=meta-llama/llama-4-maverick-17b-128e-instruct

# ===========================================
# Database
# ===========================================
ALIM_DATABASE_URL=sqlite+aiosqlite:///./data/yonca.db
ALIM_DATABASE_POOL_SIZE=10
ALIM_DATABASE_MAX_OVERFLOW=20

# ===========================================
# Redis
# ===========================================
ALIM_REDIS_URL=redis://localhost:6379/0
ALIM_REDIS_MAX_CONNECTIONS=50

# ===========================================
# Security
# ===========================================
ALIM_JWT_SECRET=dev-secret-change-in-production
ALIM_JWT_ALGORITHM=HS256
ALIM_JWT_EXPIRY_HOURS=24

# ===========================================
# Rate Limiting
# ===========================================
ALIM_RATE_LIMIT_REQUESTS_PER_MINUTE=30
ALIM_RATE_LIMIT_BURST=50

# ===========================================
# Observability
# ===========================================
ALIM_LOG_LEVEL=INFO
ALIM_LOG_FORMAT=json  # json | console
ALIM_PROMETHEUS_ENABLED=true

# ===========================================
# Langfuse (Self-Hosted Observability)
# ===========================================
ALIM_LANGFUSE_ENABLED=true
ALIM_LANGFUSE_HOST=http://localhost:3001
ALIM_LANGFUSE_SECRET_KEY=
ALIM_LANGFUSE_PUBLIC_KEY=
ALIM_LANGFUSE_SAMPLE_RATE=1.0
ALIM_LANGFUSE_DEBUG=false

# ===========================================
# App Metadata
# ===========================================
ALIM_APP_NAME=ALEM
ALIM_APP_VERSION=0.1.0
ALIM_DEFAULT_LANGUAGE=az
