# âš™ï¸ ALEM Technical Architecture

> **Purpose:** Complete technical reference for ALEM (Agronomical Logic & Evaluation Model) â€” components, data flow, and operational guidance.

---

## ğŸŒ System Context: Yonca Ecosystem

> **Important Distinction:** We are building **Yonca AI** (ALEM-powered assistant) as a sidecar to the existing **Yonca Mobile App** (Digital Umbrella's production platform).

```mermaid
%%{init: {'theme': 'neutral'}}%%
flowchart TB
    subgraph external["ğŸŒ EXTERNAL SYSTEMS (Digital Umbrella)"]
        direction TB
        yonca_mobile["ğŸ“± <b>Yonca Mobile App</b><br/><i>Production â€¢ 100k+ users</i><br/>â”â”â”â”â”â”â”â”â”<br/>â€¢ Real farmers<br/>â€¢ Real farms/parcels<br/>â€¢ EKTIS integration"]
        ektis_db["ğŸ›ï¸ <b>EKTIS Database</b><br/><i>Government â€¢ Read-only</i>"]
    end

    subgraph our_system["ğŸ¤– YONCA AI (Our System)"]
        direction TB
        alem["ğŸ§  <b>ALEM</b><br/><i>AI Model Stack</i>"]
        demo_ui["ğŸ–¥ï¸ <b>Demo UI</b><br/><i>Chainlit :8501</i>"]
    end

    yonca_mobile -.->|"Future: Real data sync"| our_system
    ektis_db --> yonca_mobile
    
    style external fill:#fff3e0,stroke:#f57c00,stroke-dasharray: 5 5
    style our_system fill:#e8f5e9,stroke:#2e7d32,stroke-width:2px
    style alem fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
```

| System | Owner | Purpose | Status |
|:-------|:------|:--------|:-------|
| **Yonca Mobile App** | Digital Umbrella | Production farming app (100k+ users) | âœ… Live |
| **EKTIS** | Government | Official farm registry | âœ… Live |
| **Yonca AI (ALEM)** | Zekalab | AI assistant sidecar | ğŸ”„ Development |

---

## ğŸ§© Five-Component System

```mermaid
%%{init: {'theme': 'neutral'}}%%
flowchart TB
    subgraph user["ğŸ‘¤ USER LAYER"]
        farmer["ğŸ§‘â€ğŸŒ¾ Farmer"]
    end

    subgraph ui["ğŸ–¥ï¸ PRESENTATION LAYER"]
        chainlit["<b>Chainlit UI</b><br/>:8501<br/>â”â”â”â”â”â”â”â”â”<br/>â€¢ Chat interface<br/>â€¢ Token streaming<br/>â€¢ Thread display<br/>â€¢ OAuth login"]
    end

    subgraph brain["ğŸ§  INTELLIGENCE LAYER"]
        langgraph["<b>LangGraph Agent</b><br/>â”â”â”â”â”â”â”â”â”<br/>â€¢ Supervisor node<br/>â€¢ Agronomist node<br/>â€¢ Weather node<br/>â€¢ Validator node"]
        llm["<b>LLM Providers</b><br/>â”â”â”â”â”â”â”â”â”<br/>â€¢ Groq (cloud)<br/>â€¢ Ollama (local)"]
    end

    subgraph data["ğŸ’¾ APP DATA LAYER"]
        direction LR
        postgres["<b>Yonca App DB</b><br/>:5433<br/>â”â”â”â”â”â”â”â”â”<br/>ğŸ“‹ App Tables:<br/>â€¢ users (OAuth)<br/>â€¢ threads, steps<br/>â€¢ user_profiles<br/>â€¢ farms, parcels<br/>â€¢ alem_personas"]
        redis["<b>Redis</b><br/>:6379<br/>â”â”â”â”â”â”â”â”â”<br/>â€¢ LangGraph checkpoints<br/>â€¢ Session state<br/>â€¢ Rate limiting"]
    end

    subgraph observe["ğŸ“Š OBSERVABILITY (Separate DB)"]
        langfuse["<b>Langfuse</b><br/>:3001<br/>â”â”â”â”â”â”â”â”â”<br/>Own database<br/>â€¢ LLM traces<br/>â€¢ Token costs<br/>â€¢ Latencies"]
    end

    farmer --> chainlit
    chainlit --> |"Direct Mode"| langgraph
    langgraph --> llm
    langgraph --> |"State checkpoints"| redis
    chainlit --> |"App data"| postgres
    langgraph --> |"Farm context"| postgres
    langgraph -.-> |"Traces"| langfuse
    langfuse -.-> |"Insights API"| postgres

    style chainlit fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style langgraph fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style postgres fill:#e8f5e9,stroke:#388e3c,stroke-width:2px
    style redis fill:#fce4ec,stroke:#c2185b,stroke-width:2px
    style langfuse fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
```

### Component Responsibility Matrix

| Component | Purpose | What It Stores | Key File |
|:----------|:--------|:---------------|:---------|
| **Chainlit** | Chat UI + thread display | UI state (delegates to App DB) | `demo-ui/app.py` |
| **Yonca App DB** | All app data | Users, farms, threads, personas | `demo-ui/data_layer.py` |
| **Redis** | Fast state + checkpoints | LangGraph state, sessions | `src/yonca/agent/memory.py` |
| **Langfuse** | LLM observability (separate DB) | Traces, costs, latencies | `src/yonca/observability/langfuse.py` |
| **LangGraph** | Agent orchestration | In-memory graph execution | `src/yonca/agent/graph.py` |

---

## ğŸ’¾ Data Ecosystem

> **Key Architecture:** THREE storage systems running in Docker â€” two PostgreSQL instances + Redis.

```mermaid
%%{init: {'theme': 'neutral'}}%%
flowchart TB
    subgraph docker["ğŸ³ Docker Compose Stack"]
        direction TB
        
        subgraph yonca_ai_data["ğŸ’¾ YONCA AI APP DATA"]
            subgraph pg_app["ğŸ˜ PostgreSQL :5433<br/><code>yonca-postgres</code>"]
                app_tables["ğŸ“‹ <b>App Tables</b><br/>â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>users, threads, steps<br/>user_profiles, farm_profiles<br/>parcels, alem_personas"]
            end
            
            subgraph redis["ğŸ”´ Redis Stack :6379<br/><code>yonca-redis</code>"]
                redis_data["âš¡ <b>Runtime State</b><br/>â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>LangGraph checkpoints<br/>Session cache<br/>Rate limits"]
            end
        end
        
        subgraph langfuse_stack["ğŸ“Š LANGFUSE STACK (Self-Contained)"]
            subgraph pg_langfuse["ğŸ˜ PostgreSQL :5432<br/><code>yonca-langfuse-db</code><br/><i>Internal only</i>"]
                lf_tables["ğŸ” <b>Auto-Managed</b><br/>â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>traces, generations<br/>scores, prompts<br/>sessions, users"]
            end
            
            langfuse_ui["ğŸŒ <b>Langfuse UI :3001</b><br/><code>yonca-langfuse</code>"]
        end
    end
    
    subgraph external["ğŸŒ FUTURE: External Data"]
        yonca_mobile["ğŸ“± Yonca Mobile<br/>(Digital Umbrella)"]
    end
    
    pg_langfuse --> langfuse_ui
    langfuse_ui -.->|"REST API<br/>read-only"| pg_app
    yonca_mobile -.->|"Hot-swap<br/>when ready"| pg_app
    
    style yonca_ai_data fill:#e8f5e9,stroke:#2e7d32,stroke-width:2px
    style langfuse_stack fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style external fill:#fff3e0,stroke:#f57c00,stroke-dasharray: 5 5
```

### ğŸ“¦ Complete Storage Inventory

| Container | Type | Port | Database/Purpose | You Manage? |
|:----------|:-----|:-----|:-----------------|:------------|
| `yonca-postgres` | PostgreSQL 15 | **:5433** | Yonca App tables | âœ… **Yes** â€” migrations, seeds |
| `yonca-redis` | Redis Stack | **:6379** | LangGraph checkpoints, sessions | âœ… **Yes** â€” ephemeral |
| `yonca-langfuse-db` | PostgreSQL 15 | *internal* | Langfuse traces (auto-managed) | âŒ **No** â€” Langfuse handles |
| `yonca-langfuse` | Next.js app | **:3001** | Observability dashboard | âŒ **No** â€” just view it |

### ğŸ” Langfuse: How It Works

**Q: Do we need to seed Langfuse with synthetic data?**  
**A: No!** Langfuse auto-populates when you interact with ALEM:

```mermaid
%%{init: {'theme': 'neutral'}}%%
sequenceDiagram
    participant U as ğŸ‘¤ Demo User
    participant A as ğŸ§  ALEM Agent
    participant LF as ğŸ“Š Langfuse
    participant DB as ğŸ˜ Langfuse DB
    
    U->>A: Send message
    A->>LF: Trace callback (auto)
    LF->>DB: INSERT trace, generation
    Note over DB: Auto-managed!<br/>No seeds needed
    
    A->>U: Response
    
    U->>LF: View dashboard :3001
    LF->>DB: Query traces
    DB->>LF: Return data
    LF->>U: Show analytics
```

**Key Points:**
1. **Traces auto-populate** â€” Every LLM call creates a trace automatically
2. **No synthetic Langfuse data needed** â€” Just use the app normally
3. **Read via API** â€” Dashboard queries Langfuse's own DB, we read via REST API
4. **Caching optional** â€” We can cache aggregated insights in our App DB

### ğŸ”‘ VS Code Database Access

To view databases directly from VS Code, install these extensions:

| Extension | ID | Purpose |
|:----------|:---|:--------|
| **Database Client** | `cweijan.vscode-database-client2` | PostgreSQL, Redis, SQLite GUI |
| **Redis** | `cweijan.vscode-redis-client` | Redis key browser |

**Connection strings:**
```bash
# Yonca App DB (your data)
postgresql://yonca:yonca_dev_password@localhost:5433/yonca

# Redis
redis://localhost:6379

# Langfuse DB (just for viewing, don't modify!)
postgresql://langfuse:langfuse_secret@localhost:5432/langfuse
# Note: Langfuse DB runs on internal port, map it in docker-compose if needed
```

> âš ï¸ **Warning:** The Langfuse DB port (5432) is internal only by default. To browse it, temporarily add port mapping: `- "5434:5432"` to `langfuse-db` in docker-compose.

### Storage Responsibilities

| Storage | Type | Tables/Keys | Purpose | Access |
|:--------|:-----|:------------|:--------|:-------|
| **Yonca App DB** | PostgreSQL :5433 | `users`, `threads`, `steps`, `feedbacks` | Conversation history | Read/Write |
| **Yonca App DB** | PostgreSQL :5433 | `user_profiles`, `farm_profiles`, `parcels` | Farm data (synthetic â†’ real) | Read/Write |
| **Langfuse DB** | PostgreSQL (internal) | `traces`, `generations`, `scores` | LLM observability | **Auto-managed** |
| **Redis** | Redis Stack :6379 | `langgraph:checkpoint:*` | LangGraph state | Read/Write |
| **Redis** | Redis Stack :6379 | `session:*`, `rate_limit:*` | Runtime cache | Read/Write |

> ğŸ’¡ **Langfuse is self-contained** â€” it manages its own PostgreSQL database. We query it via REST API for dashboard insights, but all trace data stays in Langfuse's DB. We can optionally cache aggregated insights in our App DB for faster access.

### Hot-Swap Strategy: Synthetic â†’ Real Data

The Yonca mobile platform (Digital Umbrella) already serves many users with real farm data from EKTIS. Our architecture is designed for seamless integration:

| Phase | Data Source | Status |
|:------|:------------|:-------|
| **Now** | Synthetic profiles (schema-matched) | âœ… Active |
| **Pilot** | Real users, synced from Yonca mobile | â³ Pending handoff |
| **Production** | Full EKTIS integration | ğŸ”œ Future |

> **No code changes required** â€” same `user_profiles`, `farm_profiles`, `parcels` tables, just different data source.

---

## ğŸ”„ Message Lifecycle

```mermaid
%%{init: {'theme': 'neutral'}}%%
sequenceDiagram
    participant F as ğŸ§‘â€ğŸŒ¾ Farmer
    participant C as ğŸ–¥ï¸ Chainlit
    participant G as ğŸ§  LangGraph
    participant R as ğŸ’¾ Redis
    participant P as ğŸ˜ PostgreSQL
    participant L as ğŸ“Š Langfuse

    Note over F,L: 1ï¸âƒ£ User sends message
    F->>C: "Pomidor nÉ™ vaxt suvarmalÄ±yam?"
    
    Note over C,P: 2ï¸âƒ£ Chainlit saves to PostgreSQL
    C->>P: INSERT INTO steps (threadId, input, ...)
    
    Note over C,G: 3ï¸âƒ£ LangGraph processes
    C->>G: invoke(message, thread_id)
    G->>R: Load checkpoint (if exists)
    G->>P: Query farm_profiles, parcels
    G->>L: Trace: supervisor â†’ agronomist â†’ validator
    
    Note over G,R: 4ï¸âƒ£ LangGraph saves state
    G->>R: Save checkpoint (conversation memory)
    
    Note over G,C: 5ï¸âƒ£ Response streams back
    G-->>C: Stream tokens
    C->>P: INSERT INTO steps (output, generation, ...)
    C-->>F: Display response
```

---

## ğŸ§  LangGraph Agent Structure

```
START
  â”‚
  â–¼
supervisor â”€â”€â”¬â”€â”€> end (greeting/off-topic handled)
             â”‚
             â–¼
       context_loader
             â”‚
             â”œâ”€â”€> agronomist â”€â”€> validator â”€â”€> end
             â”‚
             â””â”€â”€> weather â”€â”€â”€â”€â”€â”€> validator â”€â”€> end
```

**Graph nodes** (see `src/yonca/agent/graph.py`):
- `supervisor` â€” Routes intent, handles greetings
- `context_loader` â€” Loads farm/user context from PostgreSQL
- `agronomist` â€” Core agricultural reasoning
- `weather` â€” Weather-related queries
- `validator` â€” Output validation + safety checks

---

## ğŸš€ Operational Quick Reference

### Service URLs

| Service | URL | Health Check |
|:--------|:----|:-------------|
| **Chainlit UI** | http://localhost:8501 | Visual check |
| **PostgreSQL** | localhost:5433 | `pg_isready -h localhost -p 5433` |
| **Redis** | localhost:6379 | `redis-cli ping` |
| **Langfuse** | http://localhost:3001 | Dashboard loads |
| **Ollama** | http://localhost:11434 | `curl http://localhost:11434/api/tags` |

### Common Commands

```powershell
# Start all services
docker-compose -f docker-compose.local.yml up -d

# Run database migrations
$env:DATABASE_URL = "postgresql+asyncpg://yonca:yonca_dev_password@localhost:5433/yonca"
alembic upgrade head

# Verify Redis checkpoints
docker exec yonca-redis redis-cli KEYS "langgraph:*"

# Start Chainlit UI
cd demo-ui && chainlit run app.py -w --port 8501
```

### Verification Checklist

```sql
-- Verify Chainlit is persisting threads
SELECT id, name, "createdAt" FROM threads ORDER BY "createdAt" DESC LIMIT 5;

-- Verify messages are saved
SELECT id, type, "threadId", LEFT(output, 50) as preview FROM steps ORDER BY "createdAt" DESC LIMIT 10;
```

---

## ğŸ“‹ Implementation Gaps

| Gap | Priority | Effort |
|:----|:---------|:-------|
| Evaluation test suite | ğŸ”´ High | 5 days |
| Prometheus metrics | ğŸŸ¡ Medium | 1 day |

> See [04-TESTING-STRATEGY.md](04-TESTING-STRATEGY.md) for evaluation framework.
