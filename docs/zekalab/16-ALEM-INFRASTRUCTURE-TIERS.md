# ALEM Infrastructure Matrix

> **ALEM** = AzÉ™rbaycan LLM Ekosistem Matrisi

This document defines the four-tier infrastructure model for LLM deployment in Azerbaijan, from rapid prototyping to air-gapped sovereign installations.

---

## ğŸ—ï¸ Tier Overview

| Tier | Name | Provider | Latency | Data Residency | Cost Range |
|------|------|----------|---------|----------------|------------|
| **I** | Groq LPU | Groq Cloud | ~200ms | US (Groq servers) | $0â€“50/mo |
| **II** | Google Gemini | Google Cloud | ~400ms | EU (Vertex AI) | $20â€“300/mo |
| **III** | AzInTelecom | Sovereign Cloud | ~600ms | Azerbaijan ğŸ‡¦ğŸ‡¿ | $800â€“1,500/mo |
| **IV** | ZekaLab Custom | On-Prem | ~300ms | Customer premises | $6,500â€“12,000 one-time |

---

## âš¡ Tier I: Groq LPU â€” Rapid Prototyping

**Best for:** Hackathons, demos, MVPs, development/testing

| Specification | Value |
|--------------|-------|
| **Provider** | Groq Cloud |
| **Models** | Llama 4 Maverick 17B, Qwen 3 32B |
| **Latency** | ~200ms (P95) |
| **Throughput** | 800 tok/s |
| **Data Residency** | US (Groq servers) |
| **Cost** | Free tier available, $0â€“50/mo for dev workloads |

### Configuration

```env
YONCA_LLM_PROVIDER=groq
YONCA_GROQ_API_KEY=gsk_...
YONCA_GROQ_MODEL=meta-llama/llama-4-maverick-17b-128e-instruct
```

### Pros
- âœ… Fastest inference (LPU hardware)
- âœ… Free tier for experimentation
- âœ… Open-source models (Llama, Qwen, Mistral)
- âœ… Zero infrastructure management

### Cons
- âš ï¸ Data leaves Azerbaijan
- âš ï¸ Rate limits on free tier
- âš ï¸ External dependency

---

## ğŸ§  Tier II: Google Gemini â€” High Reasoning

**Best for:** Complex reasoning, multimodal, production pilots

| Specification | Value |
|--------------|-------|
| **Provider** | Google Cloud (Vertex AI) |
| **Models** | Gemini 2.0 Flash, Gemini 1.5 Pro |
| **Latency** | ~400ms (P95) |
| **Throughput** | 150 tok/s |
| **Data Residency** | EU (via Vertex AI region lock) |
| **Cost** | $20â€“300/mo |

### Configuration

```env
YONCA_LLM_PROVIDER=gemini
YONCA_GEMINI_API_KEY=AI...
YONCA_GEMINI_MODEL=gemini-2.0-flash-exp
```

### Pros
- âœ… Best-in-class reasoning
- âœ… Multimodal (vision, audio)
- âœ… EU data residency option
- âœ… Enterprise SLAs available

### Cons
- âš ï¸ Proprietary (closed-source)
- âš ï¸ Higher cost
- âš ï¸ Data leaves Azerbaijan

---

## ğŸ›ï¸ Tier III: AzInTelecom â€” Sovereign Cloud

**Best for:** Government, regulated industries, data sovereignty requirements

| Specification | Value |
|--------------|-------|
| **Provider** | AzInTelecom Government Cloud |
| **Models** | Llama 3.3 70B, Mistral Large |
| **Latency** | ~600ms (P95) |
| **Throughput** | 80 tok/s |
| **Data Residency** | Azerbaijan ğŸ‡¦ğŸ‡¿ (Baku DC) |
| **Cost** | $800â€“1,500/mo |

### Configuration

```env
YONCA_LLM_PROVIDER=azintelecom
YONCA_AZINTELECOM_BASE_URL=https://llm.gov.az/v1
YONCA_AZINTELECOM_API_KEY=...
YONCA_AZINTELECOM_MODEL=llama-3.3-70b
```

### Pros
- âœ… **100% data sovereignty** â€” data never leaves Azerbaijan
- âœ… Government-grade security
- âœ… Compliance with local regulations
- âœ… SLA guarantees

### Cons
- âš ï¸ Higher latency than cloud providers
- âš ï¸ Limited model selection
- âš ï¸ Higher cost

### Use Cases
- Government agricultural portals
- Ministry of Agriculture integrations
- Financial institutions (AzeriCard, banks)
- Healthcare data processing

---

## ğŸ”’ Tier IV: ZekaLab Custom â€” Private On-Prem

**Best for:** Offline farms, military, banks, air-gapped networks

| Specification | Value |
|--------------|-------|
| **Provider** | Self-hosted (customer premises) |
| **Models** | ATLLaMA 7B, Qwen 3 4B, custom fine-tunes |
| **Latency** | ~300ms (P95) |
| **Throughput** | 40 tok/s (CPU) / 200 tok/s (GPU) |
| **Data Residency** | Customer premises (air-gapped option) |
| **Cost** | $6,500â€“12,000 one-time hardware |

### Configuration (Ollama)

```env
YONCA_LLM_PROVIDER=ollama
YONCA_OLLAMA_BASE_URL=http://localhost:11434
YONCA_OLLAMA_MODEL=atllama:7b
```

### Hardware Requirements

**Minimum (CPU-only):**
- Intel i7/Xeon or AMD Ryzen 7
- 32GB RAM
- 256GB SSD
- ~$2,000

**Recommended (GPU):**
- NVIDIA RTX 4090 or A6000
- 64GB RAM
- 1TB NVMe SSD
- ~$8,000

**Enterprise (Multi-GPU):**
- 2Ã— NVIDIA A100 80GB
- 256GB RAM
- 2TB NVMe RAID
- ~$25,000

### Pros
- âœ… **Complete data isolation** â€” air-gap capable
- âœ… No internet dependency
- âœ… One-time cost (no recurring fees)
- âœ… Custom fine-tuning possible

### Cons
- âš ï¸ Requires hardware investment
- âš ï¸ Maintenance responsibility
- âš ï¸ Smaller models (7Bâ€“13B typical)

### Use Cases
- Remote farms with poor connectivity
- Military/defense applications
- Banking secure zones
- GDPR/KVKK extreme compliance

---

## ğŸ“Š Decision Matrix

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ALEM Decision Tree                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  Is data sovereignty MANDATORY?                                     â”‚
â”‚  â”œâ”€â”€ YES â†’ Is air-gap required?                                     â”‚
â”‚  â”‚         â”œâ”€â”€ YES â†’ Tier IV (On-Prem)                             â”‚
â”‚  â”‚         â””â”€â”€ NO  â†’ Tier III (AzInTelecom)                        â”‚
â”‚  â”‚                                                                  â”‚
â”‚  â””â”€â”€ NO  â†’ Is complex reasoning needed?                            â”‚
â”‚            â”œâ”€â”€ YES â†’ Is budget > $100/mo?                          â”‚
â”‚            â”‚         â”œâ”€â”€ YES â†’ Tier II (Gemini)                    â”‚
â”‚            â”‚         â””â”€â”€ NO  â†’ Tier I (Groq)                       â”‚
â”‚            â”‚                                                        â”‚
â”‚            â””â”€â”€ NO  â†’ Tier I (Groq) â€” fastest & cheapest            â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ Runtime Tier Detection

The system automatically detects the current tier based on `YONCA_LLM_PROVIDER`:

```python
from yonca.config import settings

# Get current tier
print(settings.inference_tier)  # e.g., InferenceTier.TIER_I_GROQ

# Get full specification
spec = settings.inference_tier_spec
print(f"Provider: {spec['provider']}")
print(f"Latency: {spec['latency']}")
print(f"Data Residency: {spec['data_residency']}")
```

### Banner Display

The startup banner automatically shows the current tier:

```
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  ğŸ—ï¸  ALEM Infrastructure Tier
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  âš¡  Tier I: Groq LPU
     Rapid Prototyping

     Provider: Groq Cloud
     Latency: ~200ms (P95)
     Throughput: 800 tok/s
     Data Residency: US (Groq servers)
     Cost Range: $0â€“50/mo (dev)

     Models: Llama 4 Maverick 17B, Qwen 3 32B
     Best for: Hackathons, demos, MVPs, dev/test
```

---

## ğŸš€ Migration Path

1. **Development:** Start with Tier I (Groq) â€” fast iteration, free tier
2. **Pilot:** Validate with real users on Tier I or II
3. **Production:** Choose based on data residency requirements:
   - International: Tier II (Gemini) with EU residency
   - Azerbaijan-only: Tier III (AzInTelecom)
   - Air-gapped: Tier IV (On-Prem)

---

## ğŸ“ Related Documentation

- [03-ARCHITECTURE.md](./03-ARCHITECTURE.md) â€” System architecture
- [12-DUAL-MODE-DEPLOYMENT.md](./12-DUAL-MODE-DEPLOYMENT.md) â€” Deployment modes
- [15-HARDWARE-JUSTIFICATION.md](./15-HARDWARE-JUSTIFICATION.md) â€” Hardware requirements

---

*Last updated: 2025 | ZekaLab Yonca AI Project*
