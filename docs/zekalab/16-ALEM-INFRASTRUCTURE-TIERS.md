# ALEM Infrastructure Matrix

> **ALEM** = AzÉ™rbaycan LLM Ekosistem Matrisi

This document defines the four-tier infrastructure model for LLM deployment in Azerbaijan, from rapid prototyping to air-gapped sovereign installations.

## ğŸ¯ Key Concept: Groq as Performance Benchmark

**Groq demonstrates what's possible** with open-source models (Llama, Qwen, Mixtral) on optimized hardware. All Groq benchmarks (200-300 tok/s) can be replicated with **DigiRella self-hosted infrastructure** â€” either hardware you own, or rented GPU capacity from AzInTelecom.

ğŸ‘‰ See [17-DIGIRELLA-HOSTING-PROFILES.md](17-DIGIRELLA-HOSTING-PROFILES.md) for hardware specs that match Groq performance.

---

## ğŸ—ï¸ Tier Overview

| Tier | Name | Provider | Latency | Data Residency | Cost Range |
|------|------|----------|---------|----------------|------------|
| **I** | Groq LPU | Groq Cloud | ~200ms | US (Groq servers) | $0â€“50/mo |
| **II** | Google Gemini | Google Cloud | ~400ms | EU (Vertex AI) | $20â€“300/mo |
| **III** | AzInTelecom | Sovereign Cloud | ~600ms | Azerbaijan ğŸ‡¦ğŸ‡¿ | $800â€“1,500/mo |
| **IV** | ZekaLab Custom | On-Prem | ~300ms | Customer premises | $6,500â€“12,000 one-time |

---

## âš¡ Tier I: Groq LPU â€” Rapid Prototyping (Performance Benchmark)

**Best for:** Hackathons, demos, MVPs, development/testing  
**Note:** Groq demonstrates enterprise-grade performance achievable with open-source models. Same performance available with DigiRella self-hosted (see Tier III/IV).

| Specification | Value |
|--------------|-------|
| **Provider** | Groq Cloud (LPU infrastructure) |
| **Models** | Llama 4 Maverick 17B, Qwen 3 32B (open-source) |
| **Latency** | ~200ms (P95) |
| **Throughput** | 800 tok/s (benchmark target) |
| **Data Residency** | US (Groq servers) |
| **Cost** | Free tier available, $0â€“50/mo for dev workloads |
| **Self-Hosted Equivalent** | DigiRella Lite ($2,600) or Standard ($6,300) |

### Configuration

```env
YONCA_LLM_PROVIDER=groq
YONCA_GROQ_API_KEY=gsk_...
YONCA_GROQ_MODEL=meta-llama/llama-4-maverick-17b-128e-instruct
```

### Pros
- âœ… **Fastest inference** (LPU hardware) â€” **benchmark standard**
- âœ… **100% open-source models** (Llama, Qwen, Mistral)
- âœ… Free tier for experimentation
- âœ… Zero infrastructure management
- âœ… Proves performance possible with self-hosted hardware

### Cons
- âš ï¸ Data leaves Azerbaijan (US servers)
- âš ï¸ Rate limits on free tier
- âš ï¸ External dependency (requires internet)

### Migration Path
- **Start here** for development/testing
- **Replicate performance** with DigiRella Tier III/IV for production

---

## ğŸ§  Tier II: Google Gemini â€” High Reasoning

**Best for:** Complex reasoning, multimodal, production pilots

| Specification | Value |
|--------------|-------|
| **Provider** | Google Cloud (Vertex AI) |
| **Models** | Gemini 2.0 Flash, Gemini 1.5 Pro |
| **Latency** | ~400ms (P95) |
| **Throughput** | 150 tok/s |
| **Data Residency** | EU (via Vertex AI region lock) |
| **Cost** | $20â€“300/mo |

### Configuration

```env
YONCA_LLM_PROVIDER=gemini
YONCA_GEMINI_API_KEY=AI...
YONCA_GEMINI_MODEL=gemini-2.0-flash-exp
```

### Pros
- âœ… Best-in-class reasoning
- âœ… Multimodal (vision, audio)
- âœ… EU data residency option
- âœ… Enterprise SLAs available

### Cons
- âš ï¸ Proprietary (closed-source)
- âš ï¸ Higher cost
- âš ï¸ Data leaves Azerbaijan

---

## ğŸ›ï¸ Tier III: DigiRella Cloud (AzInTelecom) â€” Sovereign Rented GPU

**Best for:** Government, regulated industries, data sovereignty requirements  
**Performance:** Matches Groq benchmarks with Azerbaijan data residency  
**Alias:** AzInTelecom Sovereign Cloud

| Specification | Value |
|--------------|-------|
| **Provider** | AzInTelecom (DigiRella Cloud partner) |
| **Models** | Llama 3.3 70B, Qwen 3 32B (same as Groq) |
| **Latency** | ~600ms (P95) âŸ¶ target: ~250ms (optimizing) |
| **Throughput** | 80 tok/s âŸ¶ target: 200+ tok/s (Groq-equivalent) |
| **Data Residency** | Azerbaijan ğŸ‡¦ğŸ‡¿ (Baku DC) |
| **Cost** | $800â€“1,500/mo (rented GPU capacity) |
| **Equivalent Groq Profile** | Groq Tier I performance + data sovereignty |

### Configuration

```env
YONCA_LLM_PROVIDER=azintelecom
YONCA_AZINTELECOM_BASE_URL=https://llm.gov.az/v1
YONCA_AZINTELECOM_API_KEY=...
YONCA_AZINTELECOM_MODEL=llama-3.3-70b
```

### Pros
- âœ… **100% data sovereignty** â€” data never leaves Azerbaijan
- âœ… Government-grade security
- âœ… Compliance with local regulations
- âœ… SLA guarantees

### Cons
- âš ï¸ Higher latency than cloud providers
- âš ï¸ Limited model selection
- âš ï¸ Higher cost

### Use Cases
- Government agricultural portals
- Ministry of Agriculture integrations
- Financial institutions (AzeriCard, banks)
- Healthcare data processing

---

## ğŸ”’ Tier IV: DigiRella Owned (Self-Hosted) â€” Private Hardware

**Best for:** Offline farms, military, banks, air-gapped networks  
**Performance:** Matches/exceeds Groq with owned hardware  
**Alias:** ZekaLab Custom, Private On-Prem

| Specification | Value |
|--------------|-------|
| **Provider** | Self-hosted hardware (DigiRella profiles) |
| **Models** | ALL Groq models (Llama 70B, Qwen 32B, Maverick 17B) |
| **Latency** | ~250ms (P95) â€” **Groq-equivalent** |
| **Throughput** | 200-300 tok/s â€” **Groq-equivalent** |
| **Data Residency** | Customer premises (air-gapped capable) |
| **Cost** | $2,600â€“145,000 one-time (see DigiRella profiles) |
| **Equivalent Groq Profile** | Full Groq performance, your hardware |

### Configuration (Ollama)

```env
YONCA_LLM_PROVIDER=ollama
YONCA_OLLAMA_BASE_URL=http://localhost:11434
YONCA_OLLAMA_MODEL=atllama:7b
```

### Hardware Requirements (DigiRella Profiles)

**DigiRella Lite** (8B models, Groq 8B-equivalent):
- 1Ã— NVIDIA RTX 4090 (24GB)
- 64GB RAM DDR5
- 1TB NVMe SSD
- **$2,600 one-time** â†’ 300+ tok/s

**DigiRella Standard** (70B models, Groq 70B-equivalent):
- 2Ã— NVIDIA RTX 5090 (64GB total)
- 128GB RAM DDR5
- 2TB NVMe SSD
- **$6,300 one-time** â†’ 200+ tok/s

**DigiRella Pro** (Enterprise scale, full Groq-equivalent):
- 8Ã— NVIDIA A100 80GB
- 512GB RAM ECC
- 10TB NVMe RAID
- **$145,000 one-time** â†’ 300+ tok/s

ğŸ‘‰ Full specs: [17-DIGIRELLA-HOSTING-PROFILES.md](17-DIGIRELLA-HOSTING-PROFILES.md)

### Pros
- âœ… **Complete data isolation** â€” air-gap capable
- âœ… No internet dependency
- âœ… One-time cost (no recurring fees)
- âœ… Custom fine-tuning possible

### Cons
- âš ï¸ Requires hardware investment
- âš ï¸ Maintenance responsibility
- âš ï¸ Smaller models (7Bâ€“13B typical)

### Use Cases
- Remote farms with poor connectivity
- Military/defense applications
- Banking secure zones
- GDPR/KVKK extreme compliance

---

## ğŸ“Š Decision Matrix

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ALEM Decision Tree                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  Is data sovereignty MANDATORY?                                     â”‚
â”‚  â”œâ”€â”€ YES â†’ Is air-gap required?                                     â”‚
â”‚  â”‚         â”œâ”€â”€ YES â†’ Tier IV (On-Prem)                             â”‚
â”‚  â”‚         â””â”€â”€ NO  â†’ Tier III (AzInTelecom)                        â”‚
â”‚  â”‚                                                                  â”‚
â”‚  â””â”€â”€ NO  â†’ Is complex reasoning needed?                            â”‚
â”‚            â”œâ”€â”€ YES â†’ Is budget > $100/mo?                          â”‚
â”‚            â”‚         â”œâ”€â”€ YES â†’ Tier II (Gemini)                    â”‚
â”‚            â”‚         â””â”€â”€ NO  â†’ Tier I (Groq)                       â”‚
â”‚            â”‚                                                        â”‚
â”‚            â””â”€â”€ NO  â†’ Tier I (Groq) â€” fastest & cheapest            â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ Runtime Tier Detection

The system automatically detects the current tier based on `YONCA_LLM_PROVIDER`:

```python
from yonca.config import settings

# Get current tier
print(settings.inference_tier)  # e.g., InferenceTier.TIER_I_GROQ

# Get full specification
spec = settings.inference_tier_spec
print(f"Provider: {spec['provider']}")
print(f"Latency: {spec['latency']}")
print(f"Data Residency: {spec['data_residency']}")
```

### Banner Display

The startup banner automatically shows the current tier:

```
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  ğŸ—ï¸  ALEM Infrastructure Tier
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  âš¡  Tier I: Groq LPU
     Rapid Prototyping

     Provider: Groq Cloud
     Latency: ~200ms (P95)
     Throughput: 800 tok/s
     Data Residency: US (Groq servers)
     Cost Range: $0â€“50/mo (dev)

     Models: Llama 4 Maverick 17B, Qwen 3 32B
     Best for: Hackathons, demos, MVPs, dev/test
```

---

## ğŸš€ Migration Path

1. **Development:** Start with Tier I (Groq) â€” fast iteration, free tier
2. **Pilot:** Validate with real users on Tier I or II
3. **Production:** Choose based on data residency requirements:
   - International: Tier II (Gemini) with EU residency
   - Azerbaijan-only: Tier III (AzInTelecom)
   - Air-gapped: Tier IV (On-Prem)

---

## ğŸ“ Related Documentation

- [17-DIGIRELLA-HOSTING-PROFILES.md](./17-DIGIRELLA-HOSTING-PROFILES.md) â€” **Groq-to-hardware mapping** â­
- [03-ARCHITECTURE.md](./03-ARCHITECTURE.md) â€” System architecture
- [12-DUAL-MODE-DEPLOYMENT.md](./12-DUAL-MODE-DEPLOYMENT.md) â€” Deployment modes
- [15-HARDWARE-JUSTIFICATION.md](./15-HARDWARE-JUSTIFICATION.md) â€” Hardware economics

---

*Last updated: 2025 | ZekaLab Yonca AI Project*
