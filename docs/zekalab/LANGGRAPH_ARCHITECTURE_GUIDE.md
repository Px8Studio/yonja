# ğŸ—ï¸ LangGraph Architecture: Dev vs Production

> **Purpose:** Crystal-clear explanation of LangGraph's role, the Dev vs Production distinction, and recommended multi-tier architecture for ZekaLab.
> **Updated:** January 22, 2026
> **Status:** Production-ready architectural guidance

---

## ğŸ¯ Executive Summary

The term **"Dev Server"** causes confusion. Here's the reality:

| Term | What It Actually Is | Persistence | Best For |
|------|-------------------|-------------|----------|
| **LangGraph Dev Server** (`langgraph dev`) | In-memory, auto-reloading server | âŒ None â€” loses all data on restart | Your laptop during coding |
| **LangGraph Server** (Production) | Same engine, persistent backend | âœ… Postgres/Redis â€” full state recovery | AzInTelecom, Docker, production |

**The key insight:** You're using the **same library** (`langgraph`), just deployed differently.

---

## ğŸ§© Component Relationship Matrix

Who does what? How do they talk?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    THE YONCA STACK                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  ğŸ“± Clients (Any language/platform)                          â”‚
â”‚  â”œâ”€ Chainlit Web UI (Python)                                 â”‚
â”‚  â”œâ”€ Yonca Mobile App (Java/Kotlin)                           â”‚
â”‚  â”œâ”€ Telegram Bot (Python)                                    â”‚
â”‚  â””â”€ cURL / Custom integrations                               â”‚
â”‚         â”‚                                                     â”‚
â”‚         â”‚ HTTP REST Calls                                     â”‚
â”‚         â–¼                                                     â”‚
â”‚  ğŸšª FastAPI (Port 8000)                                      â”‚
â”‚  â”‚  "The Doors & Windows"                                    â”‚
â”‚  â”‚  Endpoints: /api/v1/chat, /api/v1/graph/invoke, etc.     â”‚
â”‚  â”‚                                                            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚        â”‚ HTTP Internal Call                               â”‚  â”‚
â”‚        â–¼                                                  â”‚  â”‚
â”‚  ğŸ§  LangGraph Server (Port 2024)                         â”‚  â”‚
â”‚  â”‚  "The Brain / Logic Engine"                           â”‚  â”‚
â”‚  â”‚  Runs your graph: compile_agent_graph()               â”‚  â”‚
â”‚  â”‚  Executes nodes: supervisor â†’ context â†’ agronomist   â”‚  â”‚
â”‚  â”‚                                                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚        â”‚ SQL Queries                                         â”‚
â”‚        â–¼                                                      â”‚
â”‚  ğŸ—„ï¸ PostgreSQL (Port 5433)                                   â”‚
â”‚  â”‚  "The Memory"                                             â”‚
â”‚  â”‚  Stores: checkpoints, threads, users, settings           â”‚
â”‚  â”‚  LangGraph automatically saves state here                â”‚
â”‚  â”‚                                                            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚        â”‚ Caching layer                                        â”‚
â”‚        â–¼                                                      â”‚
â”‚  ğŸ’¾ Redis (Port 6379)                                        â”‚
â”‚     "The Cache"                                              â”‚
â”‚     LangGraph checkpoint speeds + conversation memory        â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Role Breakdown

| Component | Responsibility | Analogy |
|-----------|-----------------|---------|
| **LangGraph (Library)** | Graph compilation, node routing, state management | "The blueprint and construction logic" |
| **LangGraph Server** | API endpoint for executing graphs | "The factory that runs the blueprint" |
| **FastAPI** | Web framework, request routing, authentication | "The front desk and doorman" |
| **PostgreSQL** | Persistent state storage, user data, conversation history | "The filing cabinet and library" |
| **Redis** | Fast caching, checkpoint acceleration | "The desk drawer for today's important docs" |
| **Chainlit** | Web UI for conversation, user interaction | "The monitor and keyboard" |

---

## ğŸš€ Dev vs Production Deployment

### Local Development: `langgraph dev`

**When:** Running on your laptop
**How:** `langgraph dev` command
**Server:** In-memory only

```powershell
# Your laptop
$env:PYTHONPATH = "C:\path\to\yonja\src"
.\.venv\Scripts\langgraph.exe dev

# âœ… Auto-reloads when you change code
# âŒ Loses ALL data (checkpoints, memory) when server restarts
# âš ï¸ Only works for 1-2 concurrent users
```

**Data Flow:**
```
Your Code â†’ langgraph dev (in-memory) â†’ Response
              â†“ (on restart)
           ALL DATA LOST
```

### Production Deployment: Docker Container

**When:** Running on AzInTelecom or cloud servers
**How:** Docker container with Postgres backend
**Server:** Persistent, scalable

```dockerfile
# Dockerfile (production)
FROM python:3.11-slim

WORKDIR /app
COPY . .

# Install dependencies
RUN pip install -r requirements.txt

# Start LangGraph Server with Postgres persistence
CMD ["langgraph", "up", "--host", "0.0.0.0", "--port", "2024"]
```

**Data Flow:**
```
Request â†’ LangGraph Server â†’ PostgreSQL (persistent)
           â†“
        Redis Cache (fast)
           â†“
        Response

On restart:
Request â†’ LangGraph Server (reload from Postgres) â†’ Response
           âœ… ALL DATA PRESERVED
```

---

## ğŸŒ Multi-Channel Architecture

By separating **Chainlit** from **LangGraph Server**, you enable multiple clients to use the same logic:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    LangGraph Server (One Brain)              â”‚
â”‚    Port 2024: /invoke endpoint               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
        â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                          â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Chainlit    â”‚         â”‚ Yonca Mobile â”‚
   â”‚ Web UI      â”‚         â”‚ App          â”‚
   â”‚ (localhost) â”‚         â”‚ (iOS/Android)â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
            All talk to the SAME
            graph engine via HTTP
```

**Future Channels (Same Logic, Different UI):**
- âœ… Telegram Bot (`telegram_to_langgraph_bridge.py`)
- âœ… WhatsApp Bot (via Twilio)
- âœ… Yonca Mobile Deep Link Handler
- âœ… SMS Gateway (USSD-style)
- âœ… REST API for third-party integrations

**Benefit:** Write agricultural logic **once**, serve it **everywhere**.

---

## ğŸ³ Recommended ZekaLab Production Stack

For a team of 5 + production deployment to AzInTelecom:

### Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        AzInTelecom Cloud / On-Premises VM                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  Container 1: Chainlit UI                                  â”‚
â”‚  â”œâ”€ Port: 8501                                             â”‚
â”‚  â”œâ”€ Purpose: Web interface for farmers                     â”‚
â”‚  â”œâ”€ Restart policy: Always (manage separately)            â”‚
â”‚  â””â”€ Env: LANGGRAPH_HOST=http://langgraph:2024            â”‚
â”‚                                                              â”‚
â”‚  Container 2: LangGraph Server                             â”‚
â”‚  â”œâ”€ Port: 2024                                             â”‚
â”‚  â”œâ”€ Purpose: Graph execution engine                        â”‚
â”‚  â”œâ”€ Restart policy: Always                                 â”‚
â”‚  â”œâ”€ Persistence: Connects to Postgres                      â”‚
â”‚  â””â”€ Env: DATABASE_URL=postgresql://user:pass@postgres:5432â”‚
â”‚                                                              â”‚
â”‚  Container 3: FastAPI Backend                              â”‚
â”‚  â”œâ”€ Port: 8000                                             â”‚
â”‚  â”œâ”€ Purpose: REST API for integrations                    â”‚
â”‚  â”œâ”€ Restart policy: Always                                 â”‚
â”‚  â”œâ”€ Persistence: Connects to Postgres                      â”‚
â”‚  â””â”€ Routes calls to LangGraph Server                       â”‚
â”‚                                                              â”‚
â”‚  Container 4: PostgreSQL                                   â”‚
â”‚  â”œâ”€ Port: 5432 (internal only)                            â”‚
â”‚  â”œâ”€ Purpose: Persistent storage                           â”‚
â”‚  â”œâ”€ Data: Checkpoints, users, threads, farm data          â”‚
â”‚  â””â”€ Volume: /data/postgres (persistent disk)              â”‚
â”‚                                                              â”‚
â”‚  Container 5: Redis (Optional but recommended)             â”‚
â”‚  â”œâ”€ Port: 6379 (internal only)                            â”‚
â”‚  â”œâ”€ Purpose: Checkpoint cache + session storage           â”‚
â”‚  â””â”€ Volume: /data/redis (persistent disk)                 â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Docker Compose Configuration

```yaml
version: '3.8'

services:
  # 1. LangGraph Server - The Brain
  langgraph:
    build:
      context: .
      dockerfile: Dockerfile.langgraph
    ports:
      - "2024:2024"
    environment:
      DATABASE_URL: postgresql://yonca:password@postgres:5432/yonca
      REDIS_URL: redis://redis:6379
      LANGGRAPH_GRAPHS: "yonca_agent=yonca.agent.graph:compile_agent_graph"
    depends_on:
      - postgres
      - redis
    restart: always
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:2024/ok"]
      interval: 10s
      timeout: 5s
      retries: 3

  # 2. FastAPI - The API Gateway
  fastapi:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      DATABASE_URL: postgresql://yonca:password@postgres:5432/yonca
      LANGGRAPH_HOST: http://langgraph:2024
      LANGGRAPH_GRAPH_ID: yonca_agent
    depends_on:
      - postgres
      - langgraph
    restart: always
    command: ["uvicorn", "src.yonca.api.main:app", "--host", "0.0.0.0", "--port", "8000"]

  # 3. Chainlit - The Web UI
  chainlit:
    build:
      context: demo-ui
      dockerfile: Dockerfile
    ports:
      - "8501:8501"
    environment:
      LANGGRAPH_HOST: http://langgraph:2024
      LANGGRAPH_GRAPH_ID: yonca_agent
      YONCA_API_URL: http://fastapi:8000
      DATABASE_URL: postgresql://yonca:password@postgres:5432/yonca
    depends_on:
      - langgraph
      - fastapi
      - postgres
    restart: always

  # 4. PostgreSQL - The Memory
  postgres:
    image: postgres:15-alpine
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: yonca
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: yonca
    volumes:
      - postgres_data:/var/lib/postgresql/data
    restart: always
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U yonca"]
      interval: 10s
      timeout: 5s
      retries: 5

  # 5. Redis - The Cache
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: always
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3

volumes:
  postgres_data:
  redis_data:
```

---

## ğŸ’¡ Pro-Tip: `langgraph build` for Production

When deploying to production (AzInTelecom, Kubernetes, etc.), don't manually create Dockerfiles. Use the **LangGraph CLI**:

```bash
# This generates a production-ready Docker image
langgraph build -t yonca-alem:latest

# It:
# âœ… Packages your graph code
# âœ… Includes FastAPI server
# âœ… Installs all dependencies
# âœ… Sets up health checks
# âœ… Configures logging
# âœ… Optimizes image size

# Then deploy with:
docker run -d \
  -p 2024:2024 \
  -e DATABASE_URL=postgresql://... \
  -e REDIS_URL=redis://... \
  yonca-alem:latest
```

---

## ğŸ¯ Current UI Implementation

### Model Selection (Persistent)

**Location:** Header dropdown (Chat Profiles)

- User selects LLM model (e.g., "Qwen3 4B", "ATLlama")
- Selection stored in `cl.user_session.get("chat_profile")`
- Passed to LangGraph as `config["metadata"]["model"]`
- **Persists across entire session** until page refresh
- Each node respects selection: `provider = get_llm_from_config(config)`

**Flow:**
```
User picks model â†’ Header dropdown â†’ Session storage â†’ Every node call
```

### Interaction Mode (Dynamic)

**Location:** Settings sidebar (Chat Settings)

- User selects mode (Ask, Plan, Agent) **at any time**
- Selection stored in `cl.user_session["chat_settings"]`
- Can be changed **mid-conversation**
- Agent adapts behavior based on current mode

**Flow:**
```
User changes mode â†’ Sidebar panel â†’ Immediate effect on next message
```

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Chainlit Header                     â”‚
â”‚  [Logo] [ğŸ¤– Model Dropdown â–¼] [âš™ï¸]      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ Selection persists
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Chat Input Area                        â”‚
â”‚  [Message box...]                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ Click âš™ï¸
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Settings Sidebar (Slides from right)   â”‚
â”‚  ğŸ’¬ Interaction Mode: [Ask â–¼]           â”‚
â”‚  (Can change mid-conversation)          â”‚
â”‚  ğŸŒ¾ Farm Settings                       â”‚
â”‚  ğŸ“Š Preferences                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Benefits:**
- âœ… Model selection is **header-level** (always visible)
- âœ… Model selection is **persistent** (lasts whole session)
- âœ… Interaction mode is **easy to change** (sidebar button)
- âœ… Interaction mode is **dynamic** (affects next message, not history)
- âœ… Clear mental model: "what" (model) vs "how" (mode)

---

## ğŸ“š Related Documentation

- [LANGGRAPH_TESTING_GUIDE.md](LANGGRAPH_TESTING_GUIDE.md) â€” How to test graph execution
- [LANGGRAPH_DOCKER_DEPLOYMENT.md](LANGGRAPH_DOCKER_DEPLOYMENT.md) â€” Docker-specific configuration
- [09-PERFORMANCE-SLA.md](09-PERFORMANCE-SLA.md) â€” Production performance targets

---

## ğŸ“ Key Takeaways for ZekaLab

1. **LangGraph is a library**, not a monolithic "server"
2. **"Dev Server"** = in-memory, auto-reload, laptop only
3. **Production = Persistent backend** (Postgres + Redis)
4. **Separate Chainlit from LangGraph** to enable multi-channel
5. **Use `langgraph build`** when deploying to AzInTelecom
6. **Same graph logic serves all clients** (Web, Mobile, Bot, API)
