# ğŸ‡¦ğŸ‡¿ Language Interference Prevention Guide

## The Problem: Turkish Language Leakage

**Background:**  
Azerbaijani and Turkish are linguistically similar. Many general-purpose LLMs trained on Turkish data "leak" Turkish vocabulary when generating Azerbaijani text, especially when uncertain about word choice.

### Common Interference Examples

| Turkish (âŒ Wrong) | Azerbaijani (âœ… Correct) | Context |
|:------------------|:------------------------|:--------|
| eylÃ¼l | Sentyabr | September month name |
| zemin | torpaq | Soil/ground |
| sulama | suvarma | Irrigation |
| ekim | É™kin | Planting/sowing |
| tohum | toxum | Seed |
| Ã¼rÃ¼n | mÉ™hsul | Crop/product |
| hayÄ±r | xeyr | No |
| tarla | tarla | Field (same, but watch context) |

### Real Example from Testing

**User:** "BuÄŸda É™kmÉ™k Ã¼Ã§Ã¼n É™n yaxÅŸÄ± vaxt nÉ™dir?"

**âŒ Bad Response (Turkish leakage):**
> "BuÄŸday ekimi iÃ§in en iyi zaman **EylÃ¼l** ayÄ±dÄ±r. **Zemin** hazÄ±rlÄ±ÄŸÄ± yapmalÄ±sÄ±nÄ±z..."

**âœ… Good Response (Pure Azerbaijani):**
> "BuÄŸda É™kini Ã¼Ã§Ã¼n É™n yaxÅŸÄ± vaxt **Sentyabr** vÉ™ **Oktyabr** aylarÄ±dÄ±r. **TorpaÄŸÄ±** É™vvÉ™lcÉ™dÉ™n hazÄ±rlamaq lazÄ±mdÄ±r..."

---

## Our Solution: Dual-Model Strategy

Different models excel at different tasks. We use role-based model selection:

### Model Roles

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          YONCA AI MODEL ARCHITECTURE            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  REASONING    â”‚      â”‚   LANGUAGE    â”‚      â”‚
â”‚  â”‚   (Qwen)      â”‚ â”€â”€â”€> â”‚   (Llama)     â”‚      â”‚
â”‚  â”‚               â”‚      â”‚               â”‚      â”‚
â”‚  â”‚ â€¢ Math/Logic  â”‚      â”‚ â€¢ Azerbaijani â”‚      â”‚
â”‚  â”‚ â€¢ Calculation â”‚      â”‚ â€¢ Conversationâ”‚      â”‚
â”‚  â”‚ â€¢ Hidden from â”‚      â”‚ â€¢ User-facing â”‚      â”‚
â”‚  â”‚   user        â”‚      â”‚               â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚  OFFLINE FALLBACK (ATLLaMA)         â”‚       â”‚
â”‚  â”‚  â€¢ Fine-tuned for Azerbaijani       â”‚       â”‚
â”‚  â”‚  â€¢ No Turkish leakage               â”‚       â”‚
â”‚  â”‚  â€¢ Slower but highest quality       â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Model Selection Logic

**1. Cloud Mode (Groq API available):**
- **Reasoning Nodes** (irrigation calc, fertilization, etc.) â†’ `qwen3-32b`
  - Superior math/logic capabilities
  - Output is hidden, will be rewritten
- **Language Nodes** (chat, response generation) â†’ `llama-3.3-70b-versatile`
  - Better multilingual balance
  - Less Turkish leakage
  - User-facing output

**2. Local Mode (Offline/No API key):**
- **Reasoning Nodes** â†’ `qwen3:4b`
- **Language Nodes** â†’ `atllama`
  - Fine-tuned specifically for Azerbaijani
  - Best language quality
  - **Always** use for final farmer-facing responses

---

## Implementation

### 1. Enhanced System Prompt

Located in: `prompts/system/master_v1.0.0_az_strict.txt`

**Key Features:**
- âœ… **Linguistic Anchors**: Explicit list of correct Azerbaijani words
- âŒ **Negative Constraints**: Forbidden Turkish words
- ğŸ“‹ **Quality Checklist**: Self-validation before responding
- ğŸ“š **Month Names**: Russian-origin names (Sentyabr, Oktyabr, etc.)

**Example Section:**
```
<DÄ°L_QAYDALARI>
âš ï¸ KRÄ°TÄ°K: YalnÄ±z AzÉ™rbaycan dilindÉ™ danÄ±ÅŸ. TÃ¼rk dilindÉ™n sÃ¶zlÉ™ri QÆTI QADAÄANDIR.

QADAÄAN EDÄ°LMÄ°Å TÃœRK SÃ–ZLÆRÄ°:
âŒ eylÃ¼l â†’ âœ… Sentyabr
âŒ zemin â†’ âœ… torpaq
âŒ sulama â†’ âœ… suvarma
...
</DÄ°L_QAYDALARI>
```

### 2. Model Role Configuration

Located in: `src/yonca/llm/model_roles.py`

**Key Components:**
```python
MODEL_ROLES = {
    "llama-3.3-70b-versatile": {
        "role": "chat",
        "azerbaijani_quality": "high",
        "use_for": ["final_response_generation", "farmer_conversation"]
    },
    "qwen3-32b": {
        "role": "reasoning",
        "azerbaijani_quality": "medium",  # Turkish leakage risk
        "use_for": ["calculations", "internal_reasoning_nodes"]
    },
    "atllama": {
        "role": "offline_expert",
        "azerbaijani_quality": "very_high",  # Fine-tuned
        "use_for": ["offline_mode", "final_response_when_local"]
    }
}
```

**Helper Functions:**
```python
# Get model for a specific LangGraph node
get_model_for_node("response_writer", "cloud")  # â†’ llama-3.3-70b-versatile
get_model_for_node("response_writer", "local")  # â†’ atllama

# Check if rewriting needed
should_rewrite_response("qwen3-32b")  # â†’ True (rewrite with Llama/ATLLaMA)
should_rewrite_response("llama-3.3-70b-versatile")  # â†’ False (already good)
```

### 3. Updated Chat Endpoint

Located in: `src/yonca/api/routes/chat.py`

Now loads enhanced system prompt:
```python
def load_system_prompt(prompt_name: str = "master_v1.0.0_az_strict") -> str:
    """Load system prompt from file with linguistic anchors."""
    # Loads from prompts/system/master_v1.0.0_az_strict.txt
    ...

SYSTEM_PROMPT_AZ = load_system_prompt("master_v1.0.0_az_strict")
```

---

## Testing Protocol

### Test Cases

#### 1. Basic Language Test
**Prompt:**
```
Salam! BuÄŸda É™kmÉ™k Ã¼Ã§Ã¼n É™n yaxÅŸÄ± vaxt nÉ™dir?
```

**Expected (Azerbaijani):**
- âœ… "Sentyabr vÉ™ Oktyabr"
- âœ… "torpaq"
- âœ… "suvarma"

**Forbidden (Turkish):**
- âŒ "EylÃ¼l"
- âŒ "zemin"
- âŒ "sulama"

#### 2. Multi-Turn Conversation
**Turn 1:**
```
Pomidor É™kmÉ™k istÉ™yirÉ™m. NÉ™ vaxt É™kmÉ™liyÉ™m?
```

**Turn 2:**
```
Torpaq necÉ™ olmalÄ±dÄ±r?
```

**Validation:**
- Check all month names are Russian-origin
- Check all agricultural terms are Azerbaijani
- No Turkish vocabulary in any turn

#### 3. Edge Case: Turkish Input
**User writes in Turkish:**
```
Domates ekmek istiyorum. Ne zaman ekmeliyim?
```

**Expected Response:**
- Respond in Azerbaijani (not Turkish)
- Politely explain: "MÉ™n yalnÄ±z AzÉ™rbaycan dilindÉ™ cavab verirÉ™m"

### PowerShell Test Script

```powershell
# Test with enhanced system prompt
$headers = @{ 
    "Authorization" = "Bearer $env:YONCA_GROQ_API_KEY"
    "Content-Type" = "application/json" 
}

# Read the enhanced system prompt
$systemPrompt = Get-Content "prompts/system/master_v1.0.0_az_strict.txt" -Raw

$body = @{
    model = "llama-3.3-70b-versatile"
    messages = @(
        @{
            role = "system"
            content = $systemPrompt
        },
        @{
            role = "user"
            content = "BuÄŸda É™kmÉ™k Ã¼Ã§Ã¼n É™n yaxÅŸÄ± vaxt nÉ™dir?"
        }
    )
} | ConvertTo-Json -Depth 10

$response = Invoke-RestMethod `
    -Uri "https://api.groq.com/openai/v1/chat/completions" `
    -Method Post `
    -Headers $headers `
    -Body ([System.Text.Encoding]::UTF8.GetBytes($body))

$response.choices[0].message.content
```

### Quality Checklist

After each response, verify:
- [ ] All month names use Russian-origin format (Sentyabr, not EylÃ¼l)
- [ ] "torpaq" used (not "zemin")
- [ ] "suvarma" used (not "sulama")
- [ ] "toxum" used (not "tohum")
- [ ] "mÉ™hsul" used (not "Ã¼rÃ¼n")
- [ ] No other Turkish vocabulary detected
- [ ] Response is helpful and contextually appropriate

---

## Future: LangGraph Integration

When implementing LangGraph nodes:

### Example Workflow

```python
# Node 1: Calculate irrigation schedule (Qwen for math)
irrigation_plan = await qwen_node.calculate({
    "hectares": 50,
    "crop": "wheat",
    "soil_type": "clay"
})
# Output: {"schedule": [...], "water_liters": 50000, ...}
# (May contain Turkish words - doesn't matter, hidden from user)

# Node 2: Rewrite in perfect Azerbaijani (Llama for language)
final_response = await llama_node.rewrite({
    "raw_plan": irrigation_plan,
    "target_language": "azerbaijani",
    "tone": "friendly_farmer"
})
# Output: Pure Azerbaijani text shown to farmer
```

### Node Configuration

```python
from yonca.llm.model_roles import get_model_for_node, LANGGRAPH_NODE_MODELS

# Get models for cloud deployment
nodes = LANGGRAPH_NODE_MODELS["cloud"]
# {
#     "supervisor": "llama-3.3-70b-versatile",
#     "irrigation_calculator": "qwen3-32b",
#     "response_writer": "llama-3.3-70b-versatile",
#     ...
# }

# Or for local deployment
nodes = LANGGRAPH_NODE_MODELS["local"]
# {
#     "supervisor": "atllama",
#     "irrigation_calculator": "qwen3:4b",
#     "response_writer": "atllama",  # Always ATLLaMA for final output
#     ...
# }
```

---

## Recommendations

### 1. Accept the Advice âœ…

The advisor's recommendations are **highly relevant** and align with your architecture goals:

- âœ… Use Llama 3.3 70B for user-facing chat (cloud mode)
- âœ… Use Qwen for internal reasoning/calculations
- âœ… Always use ATLLaMA for offline mode
- âœ… Implement strict linguistic anchors in system prompts

### 2. Priority Actions

**Immediate (Done):**
- [x] Enhanced system prompt with negative constraints
- [x] Model role configuration
- [x] Update chat endpoint to load new prompts

**Next Steps:**
1. Test with Groq API using `llama-3.3-70b-versatile`
2. Run language quality tests (see Testing Protocol)
3. Implement LangGraph with dual-model strategy
4. Add response rewriting pipeline

**Future:**
1. Collect real farmer conversations
2. Build Azerbaijani-specific evaluation dataset
3. Fine-tune local model if needed
4. Monitor for Turkish leakage in production

### 3. Configuration Changes

**Update `.env` file:**
```bash
# Use Llama for better Azerbaijani quality
YONCA_GROQ_MODEL=llama-3.3-70b-versatile

# Keep Qwen for local reasoning
YONCA_OLLAMA_MODEL=qwen3:4b
```

**For offline mode:**
```bash
YONCA_LLM_PROVIDER=ollama
YONCA_OLLAMA_MODEL=atllama  # Best Azerbaijani quality
```

---

## References

- Enhanced System Prompt: [prompts/system/master_v1.0.0_az_strict.txt](../prompts/system/master_v1.0.0_az_strict.txt)
- Model Roles Config: [src/yonca/llm/model_roles.py](../src/yonca/llm/model_roles.py)
- Reasoning Prompt: [prompts/system/reasoning_node.txt](../prompts/system/reasoning_node.txt)
- Updated Chat Endpoint: [src/yonca/api/routes/chat.py](../src/yonca/api/routes/chat.py)

---

## Template Request

The advisor offered a **"System Prompt Master Template"** with negative constraints. 

**Status:** âœ… **Already Created**

We've implemented this as:
- `prompts/system/master_v1.0.0_az_strict.txt` - Full template with linguistic anchors
- Includes forbidden Turkish words list
- Includes quality self-check before responding
- Loaded automatically in chat endpoints

**You can request additional templates from the advisor for:**
- Intent-specific prompts (irrigation, pest control, etc.)
- Few-shot example libraries
- Context injection patterns
