# ğŸ”— Chainlit UI âŸ· MCP Setup: Relationship & Connections

## ğŸ“Œ Overview

**YES, there is a direct relationship** between the MCP button/status display in Chainlit UI and the MCP setup created. They are **tightly integrated** and work together as a complete system.

---

## ğŸ—ï¸ High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CHAINLIT UI (8501)                       â”‚
â”‚                      demo-ui/app.py                         â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ ğŸ”Œ MCP Status Indicator (UI LAYER)                   â”‚   â”‚
â”‚  â”‚ â”œâ”€ Button: View MCP Connection Status                â”‚   â”‚
â”‚  â”‚ â”œâ”€ Real-time health checks (check_mcp_health)        â”‚   â”‚
â”‚  â”‚ â”œâ”€ Status badges: âœ… Online | âŒ Offline            â”‚   â”‚
â”‚  â”‚ â””â”€ MCP_SERVICES config dict                          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                       â”‚ HTTP Requests                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                               â”‚
        â–¼                               â–¼
    PORT 7777                    PORT 2024
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ZekaLab MCP     â”‚        â”‚   LangGraph API  â”‚
â”‚  (FastMCP Server)â”‚        â”‚   (Graph Server) â”‚
â”‚                  â”‚        â”‚                  â”‚
â”‚ â€¢ /health        â”‚        â”‚ â€¢ /ok            â”‚
â”‚ â€¢ /mcp (proxy)   â”‚        â”‚ â€¢ Graph exec     â”‚
â”‚                  â”‚        â”‚                  â”‚
â”‚ âœ… Running      â”‚        â”‚ âœ… Running      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â–²                               â–²
        â”‚                               â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                             â”‚
    Configured via:              Configured via:
    - ZEKALAB_MCP_ENABLED=true   - langgraph.json
    - ZEKALAB_MCP_URL=...        - env vars
    - ZEKALAB_MCP_SECRET=...
```

---

## ğŸ”Œ The Connections (Links)

### 1ï¸âƒ£ **Configuration Connection** (Static)

#### Chainlit reads from environment:
```python
# demo-ui/app.py (lines 327-343)

MCP_SERVICES = {
    "zekalab": {
        "name": "ZekaLab Internal Rules",
        "url": os.getenv("ZEKALAB_MCP_URL", "http://localhost:7777"),  # â† Env var
        "health_endpoint": "/health",
    },
    "langgraph": {
        "name": "LangGraph API",
        "url": demo_settings.langgraph_base_url,  # â† From config
        "health_endpoint": "/ok",
    },
}
```

**Where they come from:**
- `.env` file â†’ `ZEKALAB_MCP_URL=http://localhost:7777`
- `langgraph.json` â†’ `ZEKALAB_MCP_ENABLED=true`
- Settings objects â†’ `demo_settings.langgraph_base_url`

---

### 2ï¸âƒ£ **Health Check Connection** (Dynamic)

#### Chainlit actively monitors MCP servers:
```python
# demo-ui/app.py (lines 345-370)

async def check_mcp_health(service_key: str) -> MCPServiceStatus:
    """Check health of a single MCP service."""
    service = MCP_SERVICES.get(service_key)
    url = f"{service['url']}{service['health_endpoint']}"  # Constructs URL

    try:
        async with httpx.AsyncClient(timeout=2.0) as client:
            response = await client.get(url)  # HTTP GET to /health endpoint
            # Returns: MCPServiceStatus with online/offline status
```

**What it checks:**
- `http://localhost:7777/health` â†’ ZekaLab MCP FastMCP server
- `http://localhost:2024/ok` â†’ LangGraph server

---

### 3ï¸âƒ£ **Tool Loading Connection** (Functional)

#### LangGraph loads MCP tools via adapters:
```python
# src/ALÄ°M/mcp/adapters.py (lines 33-88)

def get_mcp_client_config() -> dict[str, dict[str, Any]]:
    """Build MCP client configuration from settings."""

    # Configuration built from same env vars Chainlit reads
    if settings.zekalab_mcp_enabled:
        zekalab_config = {
            "url": f"{settings.zekalab_mcp_url}/mcp",  # Same URL, + /mcp suffix
            "transport": "http",
        }

    return config  # Dict passed to MultiServerMCPClient

async def get_mcp_tools() -> list[BaseTool]:
    """Get all tools from configured MCP servers."""
    client = create_mcp_client()
    tools = await client.get_tools()  # Fetches tools from ZekaLab FastMCP
    return tools
```

**Flow:**
1. Chainlit reads config & checks health âœ“
2. LangGraph reads **same config** & loads tools âœ“
3. Both point to same MCP server (port 7777)

---

### 4ï¸âƒ£ **Agent State Connection** (Observability)

#### MCP traces recorded in LangGraph state:
```python
# src/ALÄ°M/agent/state.py

class AgentState(TypedDict):
    # ... other fields
    mcp_traces: list[MCPTrace]  # Records every MCP call
    mcp_source: str  # "zekalab" | "openweather" | "local"
    mcp_config: dict  # Config used for this run
```

#### Chainlit displays these traces:
```python
# demo-ui/app.py (lines 2847-2900)

def _format_mcp_data_flow(mcp_traces: list[dict]) -> str | None:
    """Format MCP call traces for display."""
    # Renders:
    # - Server name (zekalab, openweather)
    # - Tool called (evaluate_irrigation_rules, etc.)
    # - Duration (42.5ms)
    # - Success/error status
    # - Data source attribution
```

---

## ğŸ“Š The Three Layers

### **Layer 1: UI (Chainlit)**
- **Role:** Display & health monitoring
- **Responsibilities:**
  - âœ… Show MCP status buttons
  - âœ… Real-time health checks
  - âœ… Display MCP data flow visualization
  - âœ… Show which data source was used

- **Files:** `demo-ui/app.py` (lines 327-400+)

### **Layer 2: Orchestration (LangGraph)**
- **Role:** Graph execution & tool binding
- **Responsibilities:**
  - âœ… Load MCP tools via adapters
  - âœ… Execute MCP calls via ToolNode
  - âœ… Record MCPTrace for observability
  - âœ… Handle fallback if MCP unavailable

- **Files:**
  - `src/ALÄ°M/agent/graph.py` (ToolNode setup)
  - `src/ALÄ°M/mcp/adapters.py` (MCP client config)

### **Layer 3: MCP Servers (Backend)**
- **Role:** Tool/resource providers
- **Responsibilities:**
  - âœ… Expose tools via standardized MCP protocol
  - âœ… Respond to health checks
  - âœ… Execute agricultural rules

- **Files:**
  - `src/ALÄ°M/mcp_server/zekalab_fastmcp.py` (ZekaLab, port 7777)
  - External: OpenWeather MCP

---

## ğŸ”— Specific Links (What Points Where)

### **Link 1: Configuration Source â†’ All Components**
```
.env (or environment)
  â”œâ”€ ZEKALAB_MCP_ENABLED â†’ adapters.py, app.py
  â”œâ”€ ZEKALAB_MCP_URL â†’ adapters.py, app.py
  â”œâ”€ ZEKALAB_MCP_SECRET â†’ adapters.py
  â””â”€ ZEKALAB_PORT â†’ zekalab_fastmcp.py (server)

langgraph.json
  â”œâ”€ ZEKALAB_MCP_ENABLED (environment)
  â”œâ”€ ZEKALAB_MCP_URL (environment)
  â””â”€ Passes env to LangGraph runtime
```

### **Link 2: Chainlit Button â†’ Health Check â†’ MCP Server**
```
User clicks "MCP Status" button (UI)
  â†“
check_mcp_health("zekalab") called
  â†“
HTTP GET http://localhost:7777/health
  â†“
ZekaLab FastMCP responds with status
  â†“
Chainlit displays badge: âœ… Online (42ms)
```

### **Link 3: Chainlit Chat â†’ LangGraph â†’ MCP Tools**
```
User sends message
  â†“
Chainlit sends to LangGraph at http://localhost:2024
  â†“
LangGraph ToolNode has MCP tools available
  â†“
If LLM decides to call MCP tool:
  â†’ LLM says: "use evaluate_irrigation_rules"
  â†’ ToolNode calls tool via MCP adapter
  â†’ HTTP to http://localhost:7777/mcp (proxy endpoint)
  â†’ Tool executes, returns result
  â†’ ToolNode records MCPTrace
  â†“
MCPTrace sent back to Chainlit
  â†“
Chainlit displays: "ğŸ“Š Data from ZekaLab (irrigation rules, 28ms)"
```

### **Link 4: Profile-Based Tool Access**
```
User selects profile: "cotton"
  â†“
Chainlit sends profile to LangGraph
  â†“
LangGraph calls: get_mcp_tools_for_profile("cotton")
  â†“
adapters.py filters by PROFILE_MCP_SERVERS["cotton"]
  = ["zekalab", "openweather"]  # Cotton gets weather + rules
  â†“
Only these tools loaded into ToolNode
  â†“
LLM can only call tools from these servers
```

---

## âœ… What SHOULD Be Linked (Currently Implemented)

### 1. **Configuration Sync** âœ…
- [ ] **Status:** All components read from same env vars
- **Verification:** Check that `.env` has these keys:
  ```bash
  ZEKALAB_MCP_ENABLED=true
  ZEKALAB_MCP_URL=http://localhost:7777
  ZEKALAB_MCP_SECRET=<optional>
  ```

### 2. **Server Discovery** âœ…
- **Status:** Both UI & LangGraph can find MCP servers
- **Verification:**
  ```bash
  curl http://localhost:7777/health  # ZekaLab
  curl http://localhost:2024/ok      # LangGraph
  ```

### 3. **Tool Loading** âœ…
- **Status:** LangGraph loads tools from MCP servers
- **Verification:**
  ```bash
  # Check MCP client config in adapters.py
  # Look for: get_mcp_tools() returns []  â†’ tools loaded
  ```

### 4. **Health Monitoring** âœ…
- **Status:** Chainlit monitors server health continuously
- **Verification:**
  ```python
  # In demo-ui/app.py
  # check_mcp_health() runs every N seconds
  # Chainlit UI shows status badges
  ```

### 5. **Observability** âœ…
- **Status:** MCPTrace records each tool call
- **Verification:**
  ```python
  # In agent/state.py
  # AgentState.mcp_traces contains list of MCPTrace
  # Chainlit displays: _format_mcp_data_flow()
  ```

---

## ğŸš€ How to Verify the Connections

### **Test 1: Config Consistency**
```bash
# Check all three read the same URL
grep -r "ZEKALAB_MCP_URL" src/ALÄ°M/mcp/adapters.py
grep -r "ZEKALAB_MCP_URL" demo-ui/app.py
grep -r "zekalab_mcp_url" langgraph.json
```

### **Test 2: Health Check End-to-End**
```bash
# 1. Start MCP server
Task: "ğŸŒ¿ ALÄ°M: ğŸ§  ZekaLab MCP Start"

# 2. Check it responds
curl http://localhost:7777/health
# Expected: {"status": "healthy", ...}

# 3. Start Chainlit
Task: "ğŸŒ¿ ALÄ°M: ğŸ–¥ï¸ UI Start"

# 4. Open UI and look for MCP status badge
# Should show: âœ… ZekaLab (12ms) â€¢ âœ… LangGraph (8ms)
```

### **Test 3: Tool Loading**
```bash
# Run MCP client test
.venv\Scripts\python.exe -m pytest tests/unit/test_mcp_server/ -v -k "test_tool"
# Should show: PASSED for each tool
```

### **Test 4: Trace Observability**
```bash
# Send a message in Chainlit that uses MCP
# Check server logs for:
# INFO mcp_tools_loaded tool_count=5 tool_names=[...]
# INFO mcp_client_created servers=['zekalab']
```

---

## ğŸ“‹ Component Checklist

### **Chainlit UI (demo-ui/app.py)**
- [ ] `MCP_SERVICES` dict defined (lines 333-343)
- [ ] `check_mcp_health()` function (lines 345-370)
- [ ] `get_all_mcp_status()` function for background monitoring
- [ ] Status badges displayed in welcome message
- [ ] `_format_mcp_data_flow()` displays MCP traces
- [ ] Data consent flow for MCP attribution

### **LangGraph (src/ALÄ°M/agent/graph.py)**
- [ ] ToolNode created with MCP tools
- [ ] `get_mcp_tools()` called in make_graph()
- [ ] Agent can invoke MCP tools
- [ ] MCPTrace recorded for each call

### **MCP Adapters (src/ALÄ°M/mcp/adapters.py)**
- [ ] `get_mcp_client_config()` builds config from env
- [ ] `create_mcp_client()` returns MultiServerMCPClient
- [ ] `get_mcp_tools()` fetches tools from all servers
- [ ] Profile-based filtering (PROFILE_MCP_SERVERS)
- [ ] Health check function

### **MCP Server (src/ALÄ°M/mcp_server/zekalab_fastmcp.py)**
- [ ] FastMCP app created
- [ ] 5 tools exposed (irrigation, fertilization, pest control, subsidy, harvest)
- [ ] 3 resources exposed (rules, crop profiles, subsidy data)
- [ ] `/health` endpoint responds
- [ ] Runs on port 7777

### **Configuration (langgraph.json + .env)**
- [ ] `ZEKALAB_MCP_ENABLED=true`
- [ ] `ZEKALAB_MCP_URL=http://localhost:7777`
- [ ] `ZEKALAB_PORT=7777` (MCP server)
- [ ] Env vars passed to LangGraph runtime

---

## ğŸ¯ Key Takeaways

| Aspect | Chainlit UI | LangGraph | MCP Server |
|:-------|:-----------|:----------|:-----------|
| **Reads config from** | `.env` vars | `langgraph.json` env | `os.getenv()` |
| **Monitors health** | âœ… Yes | âŒ No (UI does) | âŒ No (serves) |
| **Loads tools** | âŒ No | âœ… Yes via adapters | âœ… Exposes via MCP |
| **Port** | 8501 | 2024 | 7777 |
| **Connection method** | HTTP GET /health | HTTP MCP protocol | HTTP FastMCP |
| **Shows user** | Status badges | Tool execution | (invisible) |

---

## ğŸ”„ Data Flow Example

**Scenario:** User asks "How much should I irrigate?"

```
1. CHAINLIT UI (8501)
   User message sent â†’ LangGraph at http://localhost:2024

2. LANGGRAPH (2024)
   a) Loads MCP tools via adapters.py:
      - Connects to http://localhost:7777/mcp
      - Gets: [evaluate_irrigation_rules, ...]

   b) LLM processes message & decides: "need irrigation tool"

   c) ToolNode executes: evaluate_irrigation_rules()
      - Calls MCP: http://localhost:7777/mcp
      - Method: POST with tool call params

   d) Receives result
      - Records: MCPTrace(server="zekalab", tool="irrigation", ...)

   e) Returns to Chainlit with:
      - response: "Irrigate 30mm tomorrow"
      - mcp_traces: [MCPTrace(...)]

3. ZEKALAB MCP (7777)
   - Received irrigation request via HTTP
   - Executed rules (soil + temp + rainfall)
   - Returned recommendation
   - (Chainlit can also GET /health separately)

4. CHAINLIT UI (8501)
   a) Receives response + mcp_traces

   b) Displays:
      âœ“ Answer to user
      âœ“ "ğŸ“Š Data from ZekaLab (irrigation rules, 42ms)"
      âœ“ In header: "ğŸ”Œ âœ… ZekaLab (12ms) â€¢ âœ… LangGraph (8ms)"

5. BACKGROUND (Continuous)
   - Chainlit periodically calls check_mcp_health()
   - Updates status badges
   - Shows real-time connectivity
```

---

## ğŸ› ï¸ How to Add a New MCP Server

To integrate a new MCP server (e.g., Postgres MCP):

### **1. Add to MCP_SERVICES in Chainlit**
```python
# demo-ui/app.py

MCP_SERVICES = {
    "zekalab": {...},
    "langgraph": {...},
    "postgres_mcp": {  # NEW
        "name": "Database Queries",
        "url": os.getenv("POSTGRES_MCP_URL", "http://localhost:7778"),
        "health_endpoint": "/health",
    },
}
```

### **2. Add to LangGraph config**
```json
# langgraph.json
"env": {
    "ZEKALAB_MCP_ENABLED": "...",
    "POSTGRES_MCP_ENABLED": "POSTGRES_MCP_ENABLED",  # NEW
    "POSTGRES_MCP_URL": "POSTGRES_MCP_URL"  # NEW
}
```

### **3. Add to adapters config**
```python
# src/ALÄ°M/mcp/adapters.py

if settings.postgres_mcp_enabled:
    postgres_config = {
        "url": f"{settings.postgres_mcp_url}/mcp",
        "transport": "http",
    }
    config["postgres"] = postgres_config
```

### **4. Add to profile permissions**
```python
# src/ALÄ°M/mcp/adapters.py

PROFILE_MCP_SERVERS["expert"] = ["zekalab", "openweather", "postgres"]
```

### **5. Update profile UI selector**
```python
# demo-ui/app.py
# Add option to chat profile selector
```

**Now:** Chainlit shows status, LangGraph loads tools, user can use DB queries!

---

## ğŸ“š Related Documentation

- [MCP-ARCHITECTURE.md](MCP-ARCHITECTURE.md) - Overall system design
- [24-MCP-PHASE-5-DEMO-ENHANCEMENT.md](24-MCP-PHASE-5-DEMO-ENHANCEMENT.md) - UI integration details
- [23-MCP-PHASE-3-INTERNAL-SERVER.md](23-MCP-PHASE-3-INTERNAL-SERVER.md) - FastMCP server setup
- [MCP-BLUEPRINT.md](MCP-BLUEPRINT.md) - Developer guidelines

---

## ğŸ“ Summary

**The Chainlit MCP button and the MCP setup are NOT separate systemsâ€”they are parts of one integrated architecture:**

1. **Chainlit** = UI layer that monitors and displays MCP status
2. **LangGraph** = Orchestration layer that uses MCP tools
3. **MCP Servers** = Backend layer providing tools
4. **Adapters** = Bridge connecting LangGraph to MCP servers
5. **Configuration** = Shared `.env` variables connecting all parts

When you see the âœ… status badge in Chainlit, it's directly monitoring the same MCP server that LangGraph loads tools from. They're talking to the same 7777 endpoint, using the same configuration, and the UI displays what the agent actually used in its decision-making process.

**This is the "sovereign MCP stack"â€”fully integrated, fully observable, fully traceable.** ğŸŒ¾âœ¨
