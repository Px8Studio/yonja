# src/yonca/agent/nodes/agronomist.py
"""Agronomist agent node for farming advice.

The main specialist agent that provides agricultural recommendations
for irrigation, fertilization, pest control, planting, and harvesting.
"""

from pathlib import Path
from typing import Any

from langchain_core.messages import HumanMessage, AIMessage

from yonca.agent.state import AgentState, UserIntent, add_assistant_message
from yonca.config import settings
from yonca.llm.factory import get_llm_provider
from yonca.llm.providers.base import LLMMessage


# ============================================================
# Prompt Templates
# ============================================================

def load_system_prompt() -> str:
    """Load the master system prompt from file."""
    prompt_path = Path(__file__).parent.parent.parent.parent.parent / "prompts" / "system" / "master_v1.0.0_az_strict.txt"
    
    if prompt_path.exists():
        return prompt_path.read_text(encoding="utf-8")
    
    # Fallback inline prompt
    return """SÉ™n "Yonca AI" adlÄ± AzÉ™rbaycan fermerlÉ™rinÉ™ kÃ¶mÉ™k edÉ™n sÃ¼ni intellekt kÃ¶mÉ™kÃ§isisÉ™n.
YalnÄ±z AzÉ™rbaycan dilindÉ™ cavab ver. TÃ¼rk dilindÉ™n sÃ¶zlÉ™r iÅŸlÉ™tmÉ™.
Konkret vÉ™ praktiki mÉ™slÉ™hÉ™t ver."""


def build_context_prompt(state: AgentState) -> str:
    """Build context section from loaded farm/user data."""
    parts = []
    
    # User context
    user_context = state.get("user_context")
    if user_context:
        experience_map = {
            "novice": "tÉ™zÉ™ baÅŸlayan",
            "intermediate": "orta sÉ™viyyÉ™li",
            "expert": "tÉ™crÃ¼bÉ™li",
        }
        exp_level = experience_map.get(user_context.experience_level, user_context.experience_level)
        parts.append(f"""<Ä°STÄ°FADÆÃ‡Ä°>
Ad: {user_context.display_name}
TÉ™crÃ¼bÉ™: {exp_level}
TÉ™sÉ™rrÃ¼fat sayÄ±: {user_context.farm_count}
Ãœmumi sahÉ™: {user_context.total_area_ha:.1f} hektar
</Ä°STÄ°FADÆÃ‡Ä°>""")
    
    # Farm context
    farm_context = state.get("farm_context")
    if farm_context:
        crops_info = ""
        if farm_context.active_crops:
            crops = [f"- {c['crop']} ({c['parcel_id']}, {c['days_since_sowing']} gÃ¼n)" 
                     for c in farm_context.active_crops[:5]]
            crops_info = f"\nAktiv mÉ™hsullar:\n" + "\n".join(crops)
        
        parts.append(f"""<TÆSÆRRÃœFAT>
Ad: {farm_context.farm_name}
Region: {farm_context.region}
Tip: {farm_context.farm_type}
SahÉ™: {farm_context.total_area_ha:.1f} hektar
SahÉ™ sayÄ±: {farm_context.parcel_count}{crops_info}
</TÆSÆRRÃœFAT>""")
    
    # Weather context
    weather = state.get("weather")
    if weather:
        parts.append(f"""<HAVA>
Temperatur: {weather.temperature_c}Â°C
RÃ¼tubÉ™t: {weather.humidity_percent}%
YaÄŸÄ±ÅŸ: {weather.precipitation_mm} mm
KÃ¼lÉ™k: {weather.wind_speed_kmh} km/saat
Proqnoz: {weather.forecast_summary}
</HAVA>""")
    
    # Alerts
    alerts = state.get("alerts", [])
    if alerts:
        alert_lines = [f"- [{a['severity'].upper()}] {a['message_az']}" for a in alerts[:3]]
        parts.append(f"""<XÆBÆRDARLIQLAR>
{chr(10).join(alert_lines)}
</XÆBÆRDARLIQLAR>""")
    
    return "\n\n".join(parts) if parts else ""


def build_intent_prompt(intent: UserIntent | None) -> str:
    """Build intent-specific guidance for the response."""
    prompts = {
        UserIntent.IRRIGATION: """SUVARMA MÆSLÆHÆTI:
- Torpaq nÉ™mliyi vÉ™ bitki ehtiyacÄ±nÄ± qiymÉ™tlÉ™ndir
- Suvarma cÉ™dvÉ™li tÉ™klif et
- Su qÉ™naÉ™ti yollarÄ±nÄ± gÃ¶stÉ™r""",
        
        UserIntent.FERTILIZATION: """GÃœBRÆLÆMÆ MÆSLÆHÆTI:
- Torpaq analizinÉ™ É™saslanmaÄŸÄ± tÃ¶vsiyÉ™ et
- GÃ¼brÉ™ nÃ¶vlÉ™rini izah et (azot, fosfor, kalium)
- Dozaj vÉ™ vaxtlama barÉ™dÉ™ mÉ™slÉ™hÉ™t ver""",
        
        UserIntent.PEST_CONTROL: """ZÆRÆRVERÄ°CÄ° MÃœBARÄ°ZÆSÄ°:
- ÆlamÉ™tlÉ™ri soruÅŸ (varsa)
- Bioloji vÉ™ kimyÉ™vi mÃ¼barizÉ™ Ã¼sullarÄ±nÄ± tÉ™klif et
- Profilaktika tÃ¶vsiyÉ™ et""",
        
        UserIntent.HARVEST: """MÆHSUL YIÄIMI:
- YetiÅŸmÉ™ É™lamÉ™tlÉ™rini izah et
- Optimal yÄ±ÄŸÄ±m vaxtÄ±nÄ± mÃ¼É™yyÉ™n et
- Saxlama tÃ¶vsiyÉ™lÉ™ri ver""",
        
        UserIntent.PLANTING: """ÆKÄ°N MÆSLÆHÆTI:
- Torpaq hazÄ±rlÄ±ÄŸÄ±nÄ± izah et
- Ækin vaxtÄ±nÄ± tÃ¶vsiyÉ™ et
- Toxum seÃ§imi barÉ™dÉ™ mÉ™slÉ™hÉ™t ver""",
        
        UserIntent.CROP_ROTATION: """NÃ–VBÆLÄ° ÆKÄ°N:
- Torpaq saÄŸlamlÄ±ÄŸÄ±nÄ± izah et
- UyÄŸun rotasiya sxemi tÉ™klif et
- FaydalarÄ±nÄ± gÃ¶stÉ™r""",
    }
    
    return prompts.get(intent, "")


# ============================================================
# Agronomist Node
# ============================================================

async def agronomist_node(state: AgentState) -> dict[str, Any]:
    """Agronomist specialist node.
    
    Generates agricultural advice based on:
    - User's intent (irrigation, fertilization, etc.)
    - Farm context (crops, region, soil)
    - Weather conditions
    - Agronomy rules (from validator)
    
    Args:
        state: Current agent state with context loaded
        
    Returns:
        State updates with generated response
    """
    nodes_visited = state.get("nodes_visited", []).copy()
    nodes_visited.append("agronomist")
    
    user_input = state.get("current_input", "")
    intent = state.get("intent")
    
    # Build the full prompt
    system_prompt = load_system_prompt()
    context_prompt = build_context_prompt(state)
    intent_guidance = build_intent_prompt(intent)
    
    # Combine prompts
    full_system = system_prompt
    if context_prompt:
        full_system += f"\n\n<KONTEKST>\n{context_prompt}\n</KONTEKST>"
    if intent_guidance:
        full_system += f"\n\n{intent_guidance}"
    
    # Build conversation history
    messages = [LLMMessage.system(full_system)]
    
    # Add recent conversation for context
    conversation = state.get("messages", [])
    for msg in conversation[-6:]:  # Last 3 turns
        if isinstance(msg, HumanMessage):
            messages.append(LLMMessage.user(msg.content))
        elif isinstance(msg, AIMessage):
            messages.append(LLMMessage.assistant(msg.content))
    
    # Generate response
    provider = get_llm_provider()
    
    try:
        response = await provider.generate(
            messages,
            temperature=0.7,
            max_tokens=800,
        )
        
        response_text = response.content.strip()
        
        # Check for rule-based additions
        matched_rules = state.get("matched_rules", [])
        if matched_rules:
            # Append rule-based recommendations
            rule_additions = []
            for rule in matched_rules[:2]:  # Top 2 rules
                rule_additions.append(f"ğŸ“‹ {rule.get('rule_name', '')}: {rule.get('recommendation_az', '')}")
            
            if rule_additions:
                response_text += "\n\n**Qayda É™saslÄ± tÃ¶vsiyÉ™lÉ™r:**\n" + "\n".join(rule_additions)
        
        return {
            "current_response": response_text,
            "nodes_visited": nodes_visited,
            "messages": [add_assistant_message(state, response_text, "agronomist", intent)],
        }
        
    except Exception as e:
        error_response = (
            "BaÄŸÄ±ÅŸlayÄ±n, texniki problem yarandÄ±. "
            "ZÉ™hmÉ™t olmasa sualÄ±nÄ±zÄ± bir az sonra tÉ™krar yoxlayÄ±n."
        )
        
        return {
            "current_response": error_response,
            "error": str(e),
            "nodes_visited": nodes_visited,
            "messages": [add_assistant_message(state, error_response, "agronomist", intent)],
        }


async def agronomist_node_streaming(state: AgentState):
    """Streaming version of agronomist node.
    
    Yields tokens as they are generated for real-time response.
    """
    nodes_visited = state.get("nodes_visited", []).copy()
    nodes_visited.append("agronomist")
    
    user_input = state.get("current_input", "")
    intent = state.get("intent")
    
    # Build prompts
    system_prompt = load_system_prompt()
    context_prompt = build_context_prompt(state)
    intent_guidance = build_intent_prompt(intent)
    
    full_system = system_prompt
    if context_prompt:
        full_system += f"\n\n<KONTEKST>\n{context_prompt}\n</KONTEKST>"
    if intent_guidance:
        full_system += f"\n\n{intent_guidance}"
    
    messages = [LLMMessage.system(full_system)]
    
    conversation = state.get("messages", [])
    for msg in conversation[-6:]:
        if isinstance(msg, HumanMessage):
            messages.append(LLMMessage.user(msg.content))
        elif isinstance(msg, AIMessage):
            messages.append(LLMMessage.assistant(msg.content))
    
    provider = get_llm_provider()
    
    full_response = ""
    async for chunk in provider.stream(messages, temperature=0.7, max_tokens=800):
        full_response += chunk
        yield {"type": "token", "content": chunk}
    
    yield {
        "type": "final",
        "state_update": {
            "current_response": full_response,
            "nodes_visited": nodes_visited,
            "messages": [add_assistant_message(state, full_response, "agronomist", intent)],
        },
    }
